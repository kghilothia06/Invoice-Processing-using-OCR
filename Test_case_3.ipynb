{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import os\n",
    "import re\n",
    "import imutils\n",
    "from skimage.filters import threshold_local\n",
    "import argparse\n",
    "import utils\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Scanner 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([[0, 0], [maxWidth - 1, 0], [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype = \"float32\")\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Doc_Scanner(image):\n",
    "    ratio = image.shape[0]/ 500.0\n",
    "    orig = image.copy()\n",
    "    image = imutils.resize(image, height = 500)\n",
    "    \n",
    "    #cv2.imshow(\"original\", image)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    \n",
    "    #STEP 1 - Edge Detection\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    edged = cv2.Canny(gray, 75, 200)\n",
    "    print(\"Step 1: Edge Detection\")\n",
    "    #cv2.imshow(\"original\" , image)\n",
    "    #cv2.imshow(\"edged\", edged)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    \n",
    "    #STEP 2 - Finding Contour\n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sorted(cnts, key = cv2.contourArea, reverse=True)[:5]\n",
    "    \n",
    "    flag=0\n",
    "    \n",
    "    for c in cnts:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    \n",
    "        if len(approx) == 4:\n",
    "            screenCnt = approx\n",
    "            flag = 1\n",
    "            break\n",
    "        \n",
    "    print(\"Step 2: Find Contours\")\n",
    "    cv2.drawContours(image, [screenCnt], -1, (0,255,0), 2)\n",
    "    \n",
    "    #cv2.imshow(\"outline\", image)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    \n",
    "    #STEP 3 - Perspective Transform\n",
    "    warped = four_point_transform(orig, screenCnt.reshape(4,2) * ratio)\n",
    "    # convert warped image to grayscale, then threshold it to\n",
    "    # give it that 'black and white' paper effect\n",
    "    warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "    warped = cv2.resize(warped, (600,600) )\n",
    "    T = threshold_local(warped, 11, offset = 15, method = \"gaussian\")\n",
    "    warped = (warped > T).astype(\"uint8\") * 255\n",
    "    \n",
    "    # show original and scanned images\n",
    "    # imutils.resize(warped, height = 650)\n",
    "    print(\"STEP 3: Apply perspective transform\")\n",
    "    cv2.imshow(\"Original\", cv2.resize(orig, (600,600)))\n",
    "    cv2.imshow(\"Scanned\", warped)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    return warped\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here, imgQ is the template image and imgF is aligned wrt to imgQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make changes here to try out different test cases\n",
    "path_to_template_image = '0845.jpg'\n",
    "path_to_non_aligned_image = 'non-aligned.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Scan both images\n",
    "imgQ = cv2.imread(path_to_template_image)\n",
    "#imgQ = Doc_Scanner(imgQ)\n",
    "# imgQ = cv2.resize(imgQ,(w,h//3))\n",
    "imgQ = cv2.resize(imgQ, (600,600))\n",
    "\n",
    "imgF = cv2.imread(path_to_non_aligned_image)\n",
    "#imgF = Doc_Scanner(imgF)\n",
    "imgF = cv2.resize(imgF, (600,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c = imgQ.shape\n",
    "\n",
    "orb = cv2.ORB_create(100000)\n",
    "kp1, des1 = orb.detectAndCompute(imgQ,None)\n",
    "imgKp1 = cv2.drawKeypoints(imgQ,kp1,None)\n",
    "\n",
    "#cv2.imshow('Output',imgKp1)\n",
    "cv2.imshow('Template',imgQ)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Test',imgF)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "per = 5\n",
    "\n",
    "kp2, des2 = orb.detectAndCompute(imgF,None)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "match = bf.match(des2,des1)\n",
    "match.sort(key=lambda x:x.distance)\n",
    "good = match[:int(len(match)*(per/100))]\n",
    "\n",
    "imgMatch = cv2.drawMatches(imgF,kp2,imgQ,kp1,good[:40],None,flags=2)\n",
    "cv2.imshow('Rect',imgMatch)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcPoints = np.float32([kp2[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "desPoints = np.float32([kp1[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "\n",
    "M, _ = cv2.findHomography(srcPoints,desPoints,cv2.RANSAC,5.0)\n",
    "imgScan = cv2.warpPerspective(imgF,M,(w,h))\n",
    "cv2.imshow('Rect',imgScan)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to capture ROI's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectangleCoor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter type: text\n",
      "Enter Field Name: Buyer\n",
      "Enter type: Int\n",
      "Enter Field Name: Date\n",
      "Enter type: Int\n",
      "Enter Field Name: Awb No\n",
      "[[(4, 107), (415, 193), 'text', 'Buyer'], [(5, 194), (160, 223), 'Int', 'Date'], [(467, 189), (540, 229), 'Int', 'Awb No']]\n"
     ]
    }
   ],
   "source": [
    "# variables\n",
    "ix = -1\n",
    "iy = -1\n",
    "drawing = False\n",
    "\n",
    "def draw_reactangle_with_drag(event, x, y, flags, param):\n",
    "    global ix, iy, drawing, imgQ\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix = x\n",
    "        iy = y\n",
    "\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            img2 = cv2.imread(path_to_template_image)\n",
    "            img2 = cv2.resize(img2,(600,600))\n",
    "            cv2.rectangle(img2, pt1=(ix,iy), pt2=(x, y),color=(0,255,0),thickness=1)\n",
    "            imgQ = img2\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        img2 = cv2.imread(path_to_template_image)\n",
    "        img2 = cv2.resize(img2,(600,600))\n",
    "        #cv2.rectangle(img2, pt1=(ix,iy), pt2=(x, y),color=(0,255,0),thickness=1)\n",
    "        Type = input('Enter type: ')\n",
    "        Field_Name = input('Enter Field Name: ') \n",
    "        rectangleCoor.append([(ix,iy),(x,y),Type,Field_Name])\n",
    "        imgQ = img2\n",
    "\n",
    "cv2.namedWindow(winname= \"Title of Popup Window\")\n",
    "cv2.setMouseCallback(\"Title of Popup Window\", draw_reactangle_with_drag)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Title of Popup Window\", imgQ)\n",
    "    #if cv2.waitKey(10) == 27:\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        print(rectangleCoor)\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try to capture above ROI's on the aligned image 'imgScan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_processing_pipeline(cropped_img):\n",
    "    # Convert to grayscale\n",
    "    cropped_img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    #T = threshold_local(cropped_img, 11, offset = 15, method = \"mean\")\n",
    "    #cropped_img = (cropped_img > T).astype(\"uint8\") * 255\n",
    "    \n",
    "    # Creating our sharpening filter\n",
    "    filter = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "    # Applying cv2.filter2D function for Image Sharpening\n",
    "    cropped_img = cv2.filter2D(cropped_img,-1,filter)\n",
    "    \n",
    "    #Histogram Equalization\n",
    "    cropped_img = cv2.equalizeHist(cropped_img)\n",
    "    \n",
    "    #cropped_img = cv2.resize(cropped_img, (200,200))\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = {}\n",
    "for i in rectangleCoor:\n",
    "    x = i[0][0]\n",
    "    y = i[0][1]\n",
    "    w = i[1][0]\n",
    "    z = i[1][1]\n",
    "    \n",
    "    imgScan = cv2.rectangle(imgScan,(x,y),(w,z),(0,255,0),1)\n",
    "    #imgQ = cv2.rectangle(imgQ,(x,y),(w,z),(0,255,0),1)\n",
    "    #cv2.imshow('Rect',imgScan)\n",
    "    cropped_img = imgScan[i[0][1]:i[1][1] , i[0][0]:i[1][0]]\n",
    "    #cropped_img = img_processing_pipeline(cropped_img)\n",
    "    \n",
    "    field = i[2]\n",
    "    \n",
    "    cur_text = pytesseract.image_to_string(cropped_img)\n",
    "    cur_text = cur_text.replace('\\n','')\n",
    "    \n",
    "    if field != 'text':\n",
    "        cur_text = re.sub('[a-zA-Z]','',cur_text)\n",
    "        \n",
    "    #if cur_text == '':\n",
    "    #    cur_text = \"4600\"\n",
    "        \n",
    "    Result[i[3]] = cur_text\n",
    "    \n",
    "    cv2.imshow('Rect',cropped_img)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "cv2.imshow('Rect',imgScan)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Buyer': 'Ms Century Overseas17, DLF. Industrial Area,   New Dethi=110015State Code: 07',\n",
       " 'Date': '',\n",
       " 'Awb No': ''}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Result as excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=Result, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
